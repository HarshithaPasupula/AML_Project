from time import time  # we are importing the time function for the time module

import numpy as np    # we are using the numpy library for numerical  calculation
import pandas as pd   # we are using pandas for the data analysis
import matplotlib.pyplot as plt # we are using pandas for visualization

import tensorflow as tf # we are importing the machine learning tensorflow model as tf
from tensorflow import keras  # we are importing the Deep learning  API keras
from tensorflow.keras import layers # layers from keras for Neural network layers
from tensorflow.keras.models import Sequential # we are using sequential for Model creation
from tensorflow.keras.preprocessing import image # we are imorting Image processing libraries
from tensorflow.keras.callbacks import EarlyStopping # we are using early stop function to reduce computation

def graph_display(history):  #we have created the function for called graph_display for ploting the history
    acc = history.history['acc']
    val_acc = history.history['val_acc']

    loss = history.history['loss']
    val_loss = history.history['val_loss']

    plt.figure(figsize=(20, 8))
    plt.subplot(1, 2, 1)
    plt.plot(range(len(acc)), acc, label='Train Acc')
    plt.plot(range(len(val_acc)), val_acc, label='Val_Acc')
    plt.legend(loc='lower right')
    plt.title('Train & Val--Accuracy')

    plt.subplot(1, 2, 2)
    plt.plot(range(len(loss)), loss, label='Train Loss')
    plt.plot(range(len(val_loss)), val_loss, label='Val Loss')
    plt.legend(loc='upper right')
    plt.title('Train & val -- Loss')
    plt.show()

from google.colab import drive
drive.mount('/content/drive')

Bt_size = 32
height = 48 #48
width = 48 #48
epoch = 25
train_folder = "/content/drive/MyDrive/Images/Train"
val_folder ="/content/drive/MyDrive/Images/Test"
time_record = {}
time_acc = {}
time_par = {}

trn_path = tf.keras.utils.image_dataset_from_directory(
  train_folder ,
  validation_split=0.1,
  subset="training",
  seed=123,
  image_size=(height, width),
  batch_size=Bt_size)

val_path = tf.keras.utils.image_dataset_from_directory(
  val_folder,
  validation_split=0.1,
  subset="validation",
  seed=123,
  image_size=(height, width),
  batch_size=Bt_size)

name_train = trn_path.class_names

import os
for name in os.listdir('/content/drive/MyDrive/Images/Train'):
    count=[]
    for name_class in os.listdir('/content/drive/MyDrive/Images/Train'+'/'+name):
        count.append(name_class)
    print("Class name:",name,len(count))

import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

def func(path):
# Load the input image
    img = load_img(path)

    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    # Configure the ImageDataGenerator
    datagen = ImageDataGenerator(
            rotation_range=20,
            width_shift_range=0.15,
            height_shift_range=0.15,
            shear_range=0.1,
            horizontal_flip=True,
            fill_mode='nearest')

    # Generate 10 augmented images
    i = 0
    for batch in datagen.flow(x, batch_size=1,
                            save_to_dir='/content/drive/MyDrive/Images/Train/update_disgust',
                            save_prefix='aug_image',
                            save_format='jpg'):
        i += 1
        if i > 9:
            break


for name in os.listdir('/content/drive/MyDrive/Images/Train'):
    count=[]
    for name_class in os.listdir('/content/drive/MyDrive/Images/Train'+'/'+name):
        count.append(name_class)
    print("Class name:",name,len(count))

from pathlib import Path
import imghdr
plt.figure(figsize=(10, 10))
for images, labels in trn_path.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint32"))
    plt.title(name_train[labels[i]])
    plt.axis("off")
model = Sequential([
  layers.Rescaling(1./255, input_shape=(height, width, 3)),

  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.BatchNormalization(),
  layers.MaxPooling2D(),
  layers.Dropout(0.25),

  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.BatchNormalization(),
  layers.MaxPooling2D(),
  layers.Dropout(0.25),

  layers.Conv2D(128, 3, padding='same', activation='relu'),
  layers.BatchNormalization(),
  layers.MaxPooling2D(),
  layers.Dropout(0.25),

  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(len(name_train))
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['acc'])

model.summary()

start = time()

history = model.fit(
  trn_path,
  validation_data=val_path,
  epochs=epoch
)

end = time()

elapsed_time = end - start

print(f"Elapsed Time:{elapsed_time}s")


time_par["Base"] = 548258
time_record["Base"] = elapsed_time
time_acc["Base"] = history.history["val_acc"][-1]

validation_loss, validation_accuracy = model.evaluate(val_path)
print(f"Validation Accuracy: {validation_accuracy:.2%}")
time_acc["Validation"] = validation_accuracy

model = Sequential([
  layers.Rescaling(1./255, input_shape=(height, width, 3)),

  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.BatchNormalization(),
  layers.MaxPooling2D(),
  layers.Dropout(0.50),

  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.BatchNormalization(),
  layers.MaxPooling2D(),
  layers.Dropout(0.50),

  layers.Conv2D(128, 3, padding='same', activation='relu'),
  layers.BatchNormalization(),
  layers.MaxPooling2D(),
  layers.Dropout(0.50),

  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(len(name_train))
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['acc'])

model.summary()

start = time()

history = model.fit(
  trn_path,
  validation_data=val_path,
  epochs=epoch
)

end = time()

elapsed_time = end - start

print(f"Elapsed Time:{elapsed_time}s")


time_par["Base"] = 548258
time_record["Base"] = elapsed_time
time_acc["Base"] = history.history["val_acc"][-1]

validation_loss, validation_accuracy = model.evaluate(val_path)
print(f"Validation Accuracy: {validation_accuracy:.2%}")
time_acc["Validation"] = validation_accuracy

start = time()

# Specify the number of epochs you want
num_epochs = 10  # Change this value to the desired number of epochs

history = model.fit(
  trn_path,
  validation_data=val_path,
  epochs=num_epochs  # Change 'epoch' to 'num_epochs'
)

end = time()

elapsed_time = end - start

print(f"Elapsed Time:{elapsed_time}s")

time_par["Base"] = 548258
time_record["Base"] = elapsed_time
time_acc["Base"] = history.history["val_acc"][-1]

import seaborn as sns

# Get the true labels and predicted labels
y_true = []
y_pred = []
for x, y in val_path:
    y_true.extend(y.numpy())
    y_pred.extend(tf.argmax(model.predict(x), axis=-1).numpy())

# Generate the confusion matrix
cm = tf.math.confusion_matrix(y_true, y_pred)

# Normalize the confusion matrix
cm_norm = cm / tf.reduce_sum(cm)

# Display the confusion matrix as a heatmap
sns.heatmap(cm_norm, cmap='Oranges', annot=True, fmt='.1%', xticklabels=name_train, yticklabels=name_train)
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.show()

from sklearn.metrics import confusion_matrix
import itertools

# Get the true labels and predicted labels for the validation dataset
y_true = []
y_pred = []

for images, labels in val_path:
  y_true.extend(labels)
  y_pred.extend(np.argmax(model.predict(images), axis=-1))

# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Define a function to plot the confusion matrix
def plot_confusion_matrix(cm, classes):
  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
  plt.colorbar()
  tick_marks = np.arange(len(classes))
  plt.xticks(tick_marks, classes, rotation=45)
  plt.yticks(tick_marks, classes)
  thresh = cm.max() / 2.
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, cm[i, j], horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")
  plt.tight_layout()
  plt.ylabel('True label')
  plt.xlabel('Predicted label')

# Plot the confusion matrix
plt.figure(figsize=(10, 10))
plot_confusion_matrix(cm, name_train)

# Display some images and their predicted labels alongside the true labels
plt.figure(figsize=(10, 10))
for images, labels in val_path.take(1):
  for i in range(4):
    ax = plt.subplot(2, 2, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    predicted_label = name_train[y_pred[i]]
    true_label = name_train[labels[i]]
    plt.title(f"Predicted: {predicted_label}\nTrue: {true_label}")
    plt.axis("off")
